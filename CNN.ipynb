{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.0 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "a0ebea9e8627c7a82f5b530305c666d41daec6d7db7835e1c4ee94e829d84fc7"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIaFYwWOuECL"
      },
      "source": [
        "import helper_functions\n",
        "import numpy as np\n",
        "#Import keras from tensorflow and not as a standalone thing (that makes things work weird idk why)\n",
        "from tensorflow import keras\n",
        "# CNN\n",
        "from tensorflow.keras.models import Sequential  \n",
        "from tensorflow.keras.layers import Dense, Conv1D, Activation, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras.layers import InputLayer, Dropout, LSTM, BatchNormalization, Flatten, ZeroPadding1D, AveragePooling2D, BatchNormalization, MaxPooling1D, AveragePooling1D, GlobalMaxPooling1D\n",
        "import pickle\n",
        "#import helper_functions\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, Dropout, BatchNormalization\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "mgGJnqs2uECN",
        "outputId": "f1856e99-8801-491a-d048-017484b0d331"
      },
      "source": [
        "data_path = 'data'\n",
        "with open(data_path, 'rb') as f:\n",
        "    data = pickle.Unpickler(f).load()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhlX7ylPuECP",
        "outputId": "8e564743-a8f4-45e5-f2f9-10cc4682688a"
      },
      "source": [
        "# Shuffle the data\n",
        "dataToShuffle = []\n",
        "\n",
        "for log, mfcc, label in zip(data['log-mel'],data['mfccs'],data['classes']):\n",
        "    dataToShuffle.append([log,mfcc,label])\n",
        "\n",
        "ShuffledData = np.array(dataToShuffle)\n",
        "np.random.shuffle(ShuffledData)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate the data into training and test datasets\n",
        "Train = ShuffledData[:45305]\n",
        "Test = ShuffledData[45305:]\n",
        "\n",
        "log_train = []\n",
        "mfcc_train = []\n",
        "y_train = []\n",
        "\n",
        "log_test = []\n",
        "mfcc_test = []\n",
        "y_test = []\n",
        "\n",
        "for log, mfcc, label in Train:\n",
        "    log_train.append(log)\n",
        "    mfcc_train.append(mfcc)\n",
        "    y_train.append(label)\n",
        "    \n",
        "for log, mfcc, label in Test:\n",
        "    log_test.append(log)\n",
        "    mfcc_test.append(mfcc)\n",
        "    y_test.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(2):\n",
        "    label = y_train[45000+i]\n",
        "    plt.figure()\n",
        "    plt.title(\"Class id: \"+ str(label))\n",
        "    plt.imshow(x_train[45000+i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 173)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "log_test[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmIKVM5uECQ"
      },
      "source": [
        "InputShape = log_test[0].shape\n",
        "output_dim = y_test[0].shape[0]\n",
        "\n",
        "dropout = 0.2\n",
        "\n",
        "#based on model 1 from https://www.researchgate.net/publication/348432098_Speech_recognition_based_on_Convolutional_neural_networks_and_MFCC_algorithm\n",
        "# Getting around 80% accuracy\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=InputShape))\n",
        "model.add(ZeroPadding1D(padding=2))\n",
        "model.add(Conv1D(filters=256, kernel_size=10))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "#model.add(Conv1D(filters=256, kernel_size=5))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dense(output_dim))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "354/354 [==============================] - 14s 38ms/step - loss: 25.5278 - accuracy: 0.5061\n",
            "Epoch 2/12\n",
            "354/354 [==============================] - 12s 35ms/step - loss: 6.7796 - accuracy: 0.6083\n",
            "Epoch 3/12\n",
            "354/354 [==============================] - 14s 40ms/step - loss: 4.5208 - accuracy: 0.6680\n",
            "Epoch 4/12\n",
            "354/354 [==============================] - 14s 40ms/step - loss: 3.5754 - accuracy: 0.7010\n",
            "Epoch 5/12\n",
            "354/354 [==============================] - 14s 41ms/step - loss: 3.0088 - accuracy: 0.7276\n",
            "Epoch 6/12\n",
            "354/354 [==============================] - 13s 37ms/step - loss: 2.6306 - accuracy: 0.7465\n",
            "Epoch 7/12\n",
            "354/354 [==============================] - 14s 40ms/step - loss: 2.3186 - accuracy: 0.7629\n",
            "Epoch 8/12\n",
            "354/354 [==============================] - 14s 40ms/step - loss: 2.0775 - accuracy: 0.7757\n",
            "Epoch 9/12\n",
            "354/354 [==============================] - 14s 39ms/step - loss: 1.9161 - accuracy: 0.7917\n",
            "Epoch 10/12\n",
            "354/354 [==============================] - 14s 39ms/step - loss: 1.7401 - accuracy: 0.7983\n",
            "Epoch 11/12\n",
            "354/354 [==============================] - 14s 40ms/step - loss: 1.6540 - accuracy: 0.8058\n",
            "Epoch 12/12\n",
            "354/354 [==============================] - 15s 43ms/step - loss: 1.5393 - accuracy: 0.8126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x17eb12919a0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#Train the model \n",
        "x_train = np.array(mfcc_train)\n",
        "y_train = np.array(y_train)\n",
        "model.fit(x=x_train, y=y_train, epochs=12, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#based on https://towardsdatascience.com/tensorflow-speech-recognition-challenge-solution-outline-9c42dbd219c9\n",
        "#this one could be quite good, ^^ was getting like 80-85% accuracy (It's the 1D CNN)\n",
        "#was getting barely over 60% but made the model less deep (as can be seen by comments) and it got much better ~75%\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Conv1D(64,kernel_size=2,padding='same'))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv1D(64,kernel_size=2,padding='same'))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "#model.add(MaxPooling1D(2))\n",
        "\n",
        "#model.add(Conv1D(128, 3,padding='same'))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Conv1D(128, 3,padding='same'))\n",
        "#model.add(Activation('relu'))\n",
        "\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling1D(2))\n",
        "\n",
        "#model.add(Conv1D(128, 3,padding='same'))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Conv1D(128, 3,padding='same'))\n",
        "#model.add(Activation('relu'))\n",
        "\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling1D(2))\n",
        "\n",
        "model2.add(Conv1D(128, 3,padding='same'))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv1D(128, 3,padding='same'))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(MaxPooling1D(2))\n",
        "\n",
        "model2.add(GlobalMaxPooling1D())\n",
        "\n",
        "model2.add(Dense(12, activation=\"softmax\"))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "source": [
        "#Train the model \n",
        "x_train = np.array(mfcc_train)\n",
        "y_train = np.array(y_train)\n",
        "model2.fit(x=x_train, y=y_train, epochs=12, batch_size=128)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "389UPDi7uECQ"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "354/354 [==============================] - 10s 27ms/step - loss: 1.3650 - accuracy: 0.6341\n",
            "Epoch 2/12\n",
            "354/354 [==============================] - 10s 27ms/step - loss: 1.0586 - accuracy: 0.6729\n",
            "Epoch 3/12\n",
            "354/354 [==============================] - 10s 28ms/step - loss: 0.9508 - accuracy: 0.7005\n",
            "Epoch 4/12\n",
            "354/354 [==============================] - 9s 25ms/step - loss: 0.9067 - accuracy: 0.7125\n",
            "Epoch 5/12\n",
            "354/354 [==============================] - 9s 25ms/step - loss: 0.8781 - accuracy: 0.7213\n",
            "Epoch 6/12\n",
            "354/354 [==============================] - 9s 25ms/step - loss: 0.8549 - accuracy: 0.7289\n",
            "Epoch 7/12\n",
            "354/354 [==============================] - 10s 27ms/step - loss: 0.8278 - accuracy: 0.7350\n",
            "Epoch 8/12\n",
            "354/354 [==============================] - 10s 28ms/step - loss: 0.8170 - accuracy: 0.7415\n",
            "Epoch 9/12\n",
            "354/354 [==============================] - 10s 28ms/step - loss: 0.8051 - accuracy: 0.7425\n",
            "Epoch 10/12\n",
            "354/354 [==============================] - 10s 28ms/step - loss: 0.7984 - accuracy: 0.7472\n",
            "Epoch 11/12\n",
            "354/354 [==============================] - 9s 26ms/step - loss: 0.7840 - accuracy: 0.7503\n",
            "Epoch 12/12\n",
            "354/354 [==============================] - 10s 28ms/step - loss: 0.7777 - accuracy: 0.7543\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x17ecf08fca0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P8xW817uECQ"
      },
      "source": [
        "#anontherone from https://medium.com/x8-the-ai-community/audio-classification-using-cnn-coding-example-f9cbd272269e\n",
        "#this one isn't working\n",
        "input_shape=(15,173)\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Dropout(0.25))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(n_classes, activation='softmax'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 15, 173)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-9603e41edc32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m173\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    211\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    876\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2597\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2599\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2600\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2601\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\martín\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    231\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 15, 173)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuV_vUs4uECR",
        "outputId": "2d7185af-0cba-4737-a92c-0d65d3028a06"
      },
      "source": [
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyrFP5d-uECR",
        "outputId": "87d47a66-8266-47c4-9b9a-106899a20cff"
      },
      "source": [
        "#Train The Model\n",
        "x_train = np.array(mfcc_train)\n",
        "y_train = np.array(y_train)\n",
        "model.fit(x_train, y_train, batch_size=4, epochs=10, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT-3_Zf0uECS",
        "outputId": "2e829532-d8ee-4980-b796-0d3336ea0e41"
      },
      "source": [
        "# Testing the model \n",
        "x_test = np.array(mfcc_test)\n",
        "y_test = np.array(y_test)\n",
        "score = model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQoFVxXBuECS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}