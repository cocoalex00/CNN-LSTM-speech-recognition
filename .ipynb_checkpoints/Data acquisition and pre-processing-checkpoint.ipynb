{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "from keras import optimizers, losses, activations, models \n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import utils as np_utils #since Tensorflow 2, thats how you import some keras submodules such as keras.utils (it was giving me errors the other way)\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 1\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 128\n",
    "N_MFCC = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mfcc(mfcc):\n",
    "    librosa.display.specshow(mfcc)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"MFCC\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/Documents/Computer_Science/COM3025/Speech-recognition-COM3025/data/test/audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a216ba31a678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mPermitedLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'no'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'up'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'down'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'on'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'go'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'silence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mTestSubPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Get name of subdirectories or files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mTrainSubPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Get name of subdirectories or files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/Documents/Computer_Science/COM3025/Speech-recognition-COM3025/data/test/audio'"
     ]
    }
   ],
   "source": [
    "#Getting the path to the audio folders\n",
    "\n",
    "# Change with local\n",
    "#TestPath ='C:\\\\_University\\\\COM3025\\\\Coursework\\\\Speech-recognition-COM3025\\\\data\\\\raw\\\\test\\\\audio\\\\'\n",
    "#TrainPath = 'C:\\\\_University\\\\COM3025\\\\Coursework\\\\Speech-recognition-COM3025\\\\data\\\\raw\\\\train\\\\audio\\\\'\n",
    "\n",
    "#(Alex) the paths above weren't working for me so added my own, feel free to coment them out\n",
    "TestPath = 'data/test/audio'\n",
    "TrainPath = 'data/train/audio'\n",
    "\n",
    "\n",
    "PermitedLabels = ['yes','no','up','down','left','right','on','off','stop','go','silence','unknown']\n",
    "\n",
    "TestSubPath = [x.name for x in os.scandir(TestPath)] # Get name of subdirectories or files\n",
    "TrainSubPath = [x.name for x in os.scandir(TrainPath)] # Get name of subdirectories or files\n",
    "\n",
    "TrainSubPath.remove('_background_noise_')#remove directory of background noises \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of file load, plot and playback \n",
    "audio, sr = librosa.load(TestPath + TestSubPath[200])\n",
    "\n",
    "print(len(audio))\n",
    "plt.plot(audio) #Plotting the sound\n",
    "plt.show()\n",
    "\n",
    "IPython.display.Audio(audio,rate = sr)#Playing the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = librosa.feature.melspectrogram(audio, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE, n_mels=N_MFCC, fmax=8000)\n",
    "log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "librosa.display.specshow(log_mel)\n",
    "plt.xlabel(\"Hz\")\n",
    "plt.ylabel(\"Mel\")\n",
    "plt.colorbar()\n",
    "# plt.box(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(audio, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mfcc=N_MFCC)\n",
    "show_mfcc(mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the classes\n",
    "y = list(range(len(PermitedLabels)))\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "def one_hot_to_label(one_hot):\n",
    "    return PermitedLabels[np.argmax(one_hot)]\n",
    "\n",
    "def label_to_one_hot(label):\n",
    "    idx = PermitedLabels.index(label)\n",
    "    return y[idx]\n",
    "\n",
    "\n",
    "#Helper functions to pad and cut the samples\n",
    "def pad_audio(signal):\n",
    "    return np.pad(signal, pad_width = (SAMPLE_RATE - len(signal), 0), mode='constant', constant_values=(0,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get audio files for training and testing (now only a subset is selected)\n",
    "\n",
    "# Data object containing MFCC information for each train file\n",
    "data = {\n",
    "    'mfccs': [],\n",
    "    'log-mel': [],\n",
    "    'classes': []\n",
    "}\n",
    "\n",
    "# Process all files in the train set and save their MFCC\n",
    "for label in TrainSubPath:\n",
    "    \n",
    "    # Check if the data will be classified as its label or unknown\n",
    "    if label in PermitedLabels:  \n",
    "        # Add label to data\n",
    "        one_hot = label_to_one_hot(label)\n",
    "    else:\n",
    "        one_hot = label_to_one_hot('unknown')\n",
    "        \n",
    "    # Retrieve file list\n",
    "    fullpath = TrainPath + label\n",
    "    files = [x.name for x in os.scandir(fullpath)]\n",
    "\n",
    "    for file in files:\n",
    "        # Load audio\n",
    "        signal, sr = librosa.load(fullpath + \"\\\\\" + file, sr=SAMPLE_RATE)\n",
    "\n",
    "        # Check lenght of signal and pad if necessary \n",
    "        if len(signal) < SAMPLE_RATE:\n",
    "            signal = pad_audio(signal)\n",
    "\n",
    "        #Calculate mfcc and log-mel spectrogram\n",
    "        mfcc = librosa.feature.mfcc(signal, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mfcc=N_MFCC)\n",
    "        mel = librosa.feature.melspectrogram(signal, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE, n_mels=N_MFCC, fmax=8000)\n",
    "        log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "        # Capture data\n",
    "        data['mfccs'].append(mfcc)\n",
    "        data[\"log-mel\"].append(log_mel)\n",
    "        data[\"classes\"].append(one_hot)\n",
    "        \n",
    "    print(f'loaded: {label}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changed the data path addapting it to my computer (again change it when needed)\n",
    "\n",
    "#data_path = 'C:\\\\_University\\\\COM3025\\\\Coursework\\\\Speech-recognition-COM3025\\\\data\\\\prepped\\\\data'\n",
    "data_path = 'data/processed/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open(data_path, 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.Unpickler(f).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check data\n",
    "print(len(data['mfccs']))\n",
    "print(len(data['classes']))\n",
    "print(len(data['log-mel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check that the shapes of the features extracted are consistent\n",
    "mfccs = np.array(data['mfccs'])\n",
    "print(mfccs.shape)\n",
    "log_mel = np.array(data['log-mel'])\n",
    "print(log_mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking an audio file to see if it matches its label \n",
    "sampleIndex = 58000\n",
    "audio = librosa.feature.inverse.mfcc_to_audio(data['mfccs'][sampleIndex], n_mels=15)\n",
    "print(\"the label of this audio file is: \" +  one_hot_to_label(data['classes'][sampleIndex]))\n",
    "\n",
    "plt.plot(audio) #Plotting the sound\n",
    "plt.show()\n",
    "\n",
    "IPython.display.Audio(audio,rate = SAMPLE_RATE) #Playing the sound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
